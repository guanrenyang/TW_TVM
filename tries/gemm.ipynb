{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/usr/local/cuda/lib\n",
      "env: PATH=/usr/local/cuda/bin:/usr/bin\n"
     ]
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH=/usr/local/cuda/lib\n",
    "%env PATH=/usr/local/cuda/bin:/usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_gpu = tvm.target.Target(target='cuda', host='llvm')\n",
    "tgt_cpu = tvm.target.Target(target='llvm', host='llvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[n], op.name=mask)\n"
     ]
    }
   ],
   "source": [
    "mask = te.placeholder((n,), name='mask')\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var(\"n\")\n",
    "A = te.placeholder((n, ), name='A')\n",
    "B = te.compute((n,), lambda i: A[i]+mask[i], name='B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = te.create_schedule(B.op)\n",
    "\n",
    "test_kernel = tvm.build(s, [A, B, mask, n], target=tgt_cpu, name='test_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, mask: T.handle, n: T.int32):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        stride = T.var(\"int32\")\n",
      "        A_1 = T.match_buffer(A, (n,), strides=(stride,), type=\"auto\")\n",
      "        stride_1 = T.var(\"int32\")\n",
      "        B_1 = T.match_buffer(B, (n,), strides=(stride_1,), type=\"auto\")\n",
      "        n_1 = T.var(\"int32\")\n",
      "        stride_2 = T.var(\"int32\")\n",
      "        mask_1 = T.match_buffer(mask, (n_1,), strides=(stride_2,), type=\"auto\")\n",
      "        for i in range(n):\n",
      "            B_2 = T.Buffer((stride_1 * n,), data=B_1.data, type=\"auto\")\n",
      "            A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "            mask_2 = T.Buffer((stride_2 * n_1,), data=mask_1.data, type=\"auto\")\n",
      "            B_2[i * stride_1] = A_2[i * stride] + mask_2[i * stride_2]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, mask, n], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.te.tensor.Tensor'>\n",
      "-----GPU code-----\n",
      "\n",
      "#ifdef _WIN32\n",
      "  using uint = unsigned int;\n",
      "  using uchar = unsigned char;\n",
      "  using ushort = unsigned short;\n",
      "  using int64_t = long long;\n",
      "  using uint64_t = unsigned long long;\n",
      "#else\n",
      "  #define uint unsigned int\n",
      "  #define uchar unsigned char\n",
      "  #define ushort unsigned short\n",
      "  #define int64_t long long\n",
      "  #define uint64_t unsigned long long\n",
      "#endif\n",
      "extern \"C\" __global__ void __launch_bounds__(64) myadd_kernel0(float* __restrict__ C, float* __restrict__ A, float* __restrict__ B, int n, int stride, int stride_1, int stride_2) {\n",
      "  if (((int)blockIdx.x) < (n >> 6)) {\n",
      "    C[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride)] = (A[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride_1)] + B[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride_2)]);\n",
      "  } else {\n",
      "    if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < n) {\n",
      "      C[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride)] = (A[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride_1)] + B[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) * stride_2)]);\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_cuda = True\n",
    "\n",
    "tgt_gpu = tvm.target.Target(target='cuda', host='llvm')\n",
    "\n",
    "n = te.var(\"n\")\n",
    "A = te.placeholder((n, ), name='A')\n",
    "B = te.placeholder((n, ), name=\"B\")\n",
    "C = te.compute(A.shape, lambda i : A[i] + B[i], name=\"C\")\n",
    "print(type(C))\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "bx, tx = s[C].split(C.op.axis[0], factor=64)\n",
    "\n",
    "s[C].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
    "s[C].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
    "\n",
    "fadd = tvm.build(s, [A, B, C], target=tgt_gpu, name='myadd')\n",
    "\n",
    "dev = tvm.device(tgt_gpu.kind.name, 0)\n",
    "\n",
    "n=1024\n",
    "a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
    "b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
    "c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
    "fadd(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), a.numpy()+b.numpy())\n",
    "\n",
    "if(tgt_gpu.kind.name=='cuda'\n",
    "    or tgt_gpu.kind.name=='rocm'\n",
    "    or tgt_gpu.kind.name.startwith('opencl')):\n",
    "    dev_module = fadd.imported_modules[0]\n",
    "    print(\"-----GPU code-----\")\n",
    "    print(dev_module.get_source())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['myadd.cubin', 'myadd.o', 'myadd.so', 'myadd.tvm_meta.json']\n"
     ]
    }
   ],
   "source": [
    "from tvm.contrib import cc\n",
    "from tvm.contrib import utils\n",
    "\n",
    "temp = utils.tempdir()\n",
    "fadd.save(temp.relpath('myadd.o')) # `fadd` is host function\n",
    "fadd.imported_modules[0].save(temp.relpath('myadd.cubin')) # `fadd.imported_functions[0]` is the gpu kernel\n",
    "cc.create_shared(temp.relpath('myadd.so'), [temp.relpath('myadd.o')])\n",
    "print(temp.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fadd1 = tvm.runtime.load_module(temp.relpath('myadd.so'))\n",
    "fadd1_dev = tvm.runtime.load_module(temp.relpath('myadd.cubin'))\n",
    "fadd1.import_module(fadd1_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fadd1(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), a.numpy()+b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fadd.export_library(temp.relpath('myadd_pack.so'))\n",
    "fadd2 = tvm.runtime.load_module(temp.relpath('myadd_pack.so'))\n",
    "fadd2(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), a.numpy()+b.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm-build-binding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "400f399043f899df7d546bcb6063b1538c013427ed509bbd25e6c99d0cce4f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
